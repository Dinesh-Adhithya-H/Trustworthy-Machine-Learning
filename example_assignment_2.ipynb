{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd:  c:\\Users\\HP\\OneDrive\\Documents\\GitHub\\Trustworthy-Machine-Learning\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# Do install: \n",
    "# conda install onnx\n",
    "# conda install onnxruntime\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import json\n",
    "import io\n",
    "import sys\n",
    "import base64\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple\n",
    "import pickle\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print('cwd: ', cwd)\n",
    "\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if not self.transform is None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 78446225, 'port': '9056'}\n"
     ]
    }
   ],
   "source": [
    "### REQUESTING NEW API ###\n",
    "TOKEN = \"75184352\" # to be changed according to your token (given to you for the assignments)\n",
    "\n",
    "response = requests.get(\"http://34.71.138.79:9090\" + \"/stealing_launch\", headers={\"token\": TOKEN})\n",
    "answer = response.json()\n",
    "\n",
    "print(answer)  # {\"seed\": \"SEED\", \"port\": PORT}\n",
    "if 'detail' in answer:\n",
    "    sys.exit(1)\n",
    "\n",
    "# save the values\n",
    "SEED = str(answer['seed'])\n",
    "PORT = str(answer['port'])\n",
    "\n",
    "# SEED = \"1868949\"\n",
    "# PORT = \"9002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUERYING THE API ###\n",
    "\n",
    "def model_stealing(images, port):\n",
    "    endpoint = \"/query\"\n",
    "    url = f\"http://34.71.138.79:{port}\" + endpoint\n",
    "    image_data = []\n",
    "    \n",
    "    for img in images:\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr.seek(0)\n",
    "        img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "        image_data.append(img_base64)\n",
    "    \n",
    "    payload = json.dumps(image_data)\n",
    "    response = requests.get(url, files={\"file\": payload}, headers={\"token\": TOKEN})\n",
    "    if response.status_code == 200:\n",
    "        representation = response.json()[\"representations\"]\n",
    "        return representation\n",
    "    else:\n",
    "        raise Exception(\n",
    "            f\"Model stealing failed. Code: {response.status_code}, content: {response.json()}\"\n",
    "        )\n",
    "\n",
    "dataset = torch.load(\"ModelStealingPub.pt\")\n",
    "out = model_stealing([dataset.imgs[idx] for idx in range(1000)], port=PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "def model_stealing_tensor(images, port):\n",
    "    endpoint = \"/query\"\n",
    "    url = f\"http://34.71.138.79:{port}\" + endpoint\n",
    "    \n",
    "    to_pil = ToPILImage()\n",
    "\n",
    "    \n",
    "    image_data = []\n",
    "    for img_tensor in images:\n",
    "        img = to_pil(img_tensor)  # Convert tensor to PIL Image\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr.seek(0)\n",
    "        img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "        image_data.append(img_base64)\n",
    "    \n",
    "    payload = json.dumps(image_data)\n",
    "    response = requests.get(url, files={\"file\": payload}, headers={\"token\": TOKEN})\n",
    "    if response.status_code == 200:\n",
    "        representation = response.json()[\"representations\"]\n",
    "        return representation\n",
    "    else:\n",
    "        raise Exception(\n",
    "            f\"Model stealing failed. Code: {response.status_code}, content: {response.json()}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1024\n",
      "0.24687974154949188\n"
     ]
    }
   ],
   "source": [
    "# 1000 representations in a list\n",
    "print(len(out))\n",
    "\n",
    "# representation 1\n",
    "print(len(out[0]))\n",
    "\n",
    "# first element in the representation\n",
    "print(out[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Store the output in a file.\n",
    "# Be careful to store all the outputs from the API since the number of queries is limited.\n",
    "with open('out.pickle', 'wb') as handle:\n",
    "    pickle.dump(out, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Restore the output from the file.\n",
    "with open('out.pickle', 'rb') as handle:\n",
    "    out = pickle.load(handle)\n",
    "\n",
    "print(len(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L2': 34.66728973388672}\n"
     ]
    }
   ],
   "source": [
    "#### SUBMISSION ####\n",
    "\n",
    "# Create a dummy model\n",
    "model = nn.Sequential(nn.Flatten(), nn.Linear(32*32*3, 1024))\n",
    "\n",
    "path = 'dummy_submission.onnx'\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    torch.randn(1, 3, 32, 32),\n",
    "    path,\n",
    "    export_params=True,\n",
    "    input_names=[\"x\"],\n",
    ")\n",
    "\n",
    "#### Tests ####\n",
    "\n",
    "# (these are being ran on the eval endpoint for every submission)\n",
    "with open(path, \"rb\") as f:\n",
    "    model = f.read()\n",
    "    try:\n",
    "        stolen_model = ort.InferenceSession(model)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Invalid model, {e=}\")\n",
    "    try:\n",
    "        out = stolen_model.run(\n",
    "            None, {\"x\": np.random.randn(1, 3, 32, 32).astype(np.float32)}\n",
    "        )[0][0]\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Some issue with the input, {e=}\")\n",
    "    assert out.shape == (1024,), \"Invalid output shape\"\n",
    "\n",
    "# Send the model to the server\n",
    "response = requests.post(\"http://34.71.138.79:9090/stealing\", files={\"file\": open(path, \"rb\")}, headers={\"token\": TOKEN, \"seed\": SEED})\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make a surrogate model\n",
    "# query the API, then use contrastive learning to train a surrogate model\n",
    "# adv image = image + epsilon * sign(d(SM)/d(image))\n",
    "\n",
    "# generate adversarial examples to attack the surrogate model\n",
    "# query the API with the adversarial examples\n",
    "\n",
    "# retrain the surrogate model with the adversarial examples\n",
    "# reapeat the process for a few iterations\n",
    "# then submit the surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a surrogate model with high capacity, input torch.Size([3, 32, 32]) and output torch.Size([1024])\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class SurrogateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SurrogateModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(256 * 4 * 4, 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = SurrogateModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = surrogate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(images_dataset[0][0].unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a contrastive loss function\n",
    "def contrastive_loss(output1, output2):\n",
    "    return torch.dist(output1, output2, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(\"ModelStealingPub.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
    "\n",
    "# Convert all images to 3-channel images\n",
    "images = [to_tensor(img.convert(\"RGB\")) for img in dataset.imgs]\n",
    "# Convert the list to a tensor\n",
    "inputs_tensor = torch.stack(images)\n",
    "# Create a TensorDataset\n",
    "images_dataset = TensorDataset(inputs_tensor)\n",
    "# Create a DataLoader\n",
    "images_loader = torch.utils.data.DataLoader(images_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2468763291835785,\n",
       " 0.7640955448150635,\n",
       " 2.0415852069854736,\n",
       " 0.6812667846679688,\n",
       " 0.639507532119751,\n",
       " 1.4539283514022827,\n",
       " 0.4100433886051178,\n",
       " -0.5971630215644836,\n",
       " -2.775956153869629,\n",
       " -0.9223045110702515,\n",
       " -0.8140902519226074,\n",
       " -0.023410465568304062,\n",
       " 0.42235273122787476,\n",
       " -0.42530572414398193,\n",
       " -0.5513540506362915,\n",
       " 0.6688016057014465,\n",
       " -0.5512476563453674,\n",
       " 0.1592712253332138,\n",
       " 3.0318188667297363,\n",
       " -1.4227402210235596,\n",
       " 0.4780133366584778,\n",
       " -0.8373602032661438,\n",
       " -0.02401147410273552,\n",
       " -1.0113649368286133,\n",
       " 0.5119370818138123,\n",
       " 1.4763036966323853,\n",
       " -0.7429710030555725,\n",
       " -0.20326977968215942,\n",
       " 0.03961934149265289,\n",
       " 0.9434902667999268,\n",
       " -0.05623319745063782,\n",
       " 0.7350677251815796,\n",
       " -0.9103511571884155,\n",
       " 0.28039059042930603,\n",
       " 0.5605455040931702,\n",
       " 0.8105497360229492,\n",
       " 0.4262767732143402,\n",
       " 1.1831971406936646,\n",
       " 0.5435795187950134,\n",
       " -0.6307848691940308,\n",
       " 0.9884937405586243,\n",
       " -0.244427889585495,\n",
       " -5.723690032958984,\n",
       " -0.06671316176652908,\n",
       " -0.244911789894104,\n",
       " -0.5658474564552307,\n",
       " -2.157815933227539,\n",
       " 1.417226791381836,\n",
       " -0.2954678237438202,\n",
       " -0.8194423317909241,\n",
       " 0.7374253869056702,\n",
       " -1.11514413356781,\n",
       " 1.1808953285217285,\n",
       " 0.6555313467979431,\n",
       " -0.29116374254226685,\n",
       " -0.8050702214241028,\n",
       " 0.6407700181007385,\n",
       " 1.193849802017212,\n",
       " -0.21214167773723602,\n",
       " -1.001883864402771,\n",
       " 0.07706045359373093,\n",
       " -0.20916101336479187,\n",
       " 0.6292724609375,\n",
       " 1.5899022817611694,\n",
       " 1.449615240097046,\n",
       " -0.9027498960494995,\n",
       " 0.2644505202770233,\n",
       " -0.6525667309761047,\n",
       " -0.6378364562988281,\n",
       " 0.4263963997364044,\n",
       " -0.6712568402290344,\n",
       " 0.5842806100845337,\n",
       " -1.454011082649231,\n",
       " -0.4316365420818329,\n",
       " 0.9573678374290466,\n",
       " 0.6460464596748352,\n",
       " -0.2197217047214508,\n",
       " -0.7218777537345886,\n",
       " 1.0123412609100342,\n",
       " -1.406028151512146,\n",
       " 0.22715212404727936,\n",
       " -0.4722345471382141,\n",
       " -0.4531712532043457,\n",
       " -0.18598879873752594,\n",
       " -0.6118326187133789,\n",
       " -2.482210874557495,\n",
       " 2.6034047603607178,\n",
       " -1.3637217283248901,\n",
       " -0.9769899249076843,\n",
       " -0.9974629878997803,\n",
       " -0.3620203137397766,\n",
       " -0.2844313085079193,\n",
       " 0.14323002099990845,\n",
       " 0.9582504630088806,\n",
       " 0.2338820844888687,\n",
       " -0.16791388392448425,\n",
       " 0.2804889380931854,\n",
       " 1.7719132900238037,\n",
       " -0.2330159693956375,\n",
       " -0.6480175852775574,\n",
       " 0.4484422504901886,\n",
       " 0.5076249241828918,\n",
       " -1.0207830667495728,\n",
       " 0.409775972366333,\n",
       " -0.3961448073387146,\n",
       " -4.614222526550293,\n",
       " 0.1857435554265976,\n",
       " 1.6000040769577026,\n",
       " -0.397467702627182,\n",
       " -0.5821661949157715,\n",
       " 1.1556789875030518,\n",
       " 0.6269012689590454,\n",
       " 0.7713414430618286,\n",
       " -0.6888464689254761,\n",
       " -1.4981938600540161,\n",
       " 0.907657265663147,\n",
       " 0.9019234776496887,\n",
       " 0.7588189840316772,\n",
       " 0.2566016912460327,\n",
       " 0.3699907064437866,\n",
       " -1.8331671953201294,\n",
       " 0.03163085877895355,\n",
       " -0.07740761339664459,\n",
       " -2.189046859741211,\n",
       " 0.14157827198505402,\n",
       " -2.2783875465393066,\n",
       " 0.8653789162635803,\n",
       " 0.9774473309516907,\n",
       " 0.14567363262176514,\n",
       " 1.2423694133758545,\n",
       " -0.5144706964492798,\n",
       " 0.891025960445404,\n",
       " 0.2320525050163269,\n",
       " 0.22039783000946045,\n",
       " -0.15348628163337708,\n",
       " -0.002170738996937871,\n",
       " 0.040012236684560776,\n",
       " 0.869179904460907,\n",
       " 0.48553481698036194,\n",
       " -0.4385727643966675,\n",
       " 0.29246899485588074,\n",
       " -0.5022917985916138,\n",
       " 0.5735408663749695,\n",
       " -0.09321147948503494,\n",
       " 0.16546832025051117,\n",
       " -0.557023823261261,\n",
       " -2.596419334411621,\n",
       " -0.02237659879028797,\n",
       " 1.450544834136963,\n",
       " -0.4365183115005493,\n",
       " 1.0250277519226074,\n",
       " -0.9077058434486389,\n",
       " 0.36571961641311646,\n",
       " -0.3268337845802307,\n",
       " 0.5862789154052734,\n",
       " -0.4298204481601715,\n",
       " 1.897544503211975,\n",
       " -0.5045245289802551,\n",
       " 0.6193379163742065,\n",
       " -0.5580098032951355,\n",
       " -0.7488613128662109,\n",
       " 0.5174373984336853,\n",
       " -0.24838308990001678,\n",
       " -0.5198614597320557,\n",
       " -1.0664185285568237,\n",
       " -0.08649270981550217,\n",
       " 0.5629593729972839,\n",
       " -0.5913143754005432,\n",
       " -0.4117948114871979,\n",
       " -0.755910336971283,\n",
       " -0.6159892678260803,\n",
       " -0.9687543511390686,\n",
       " -5.20034646987915,\n",
       " 0.152848020195961,\n",
       " 0.716235339641571,\n",
       " -0.0148871298879385,\n",
       " -0.08788128197193146,\n",
       " -0.9810896515846252,\n",
       " -0.0025329033378511667,\n",
       " 0.932013213634491,\n",
       " 0.7405510544776917,\n",
       " -0.31206077337265015,\n",
       " -0.8945201635360718,\n",
       " 0.5496047139167786,\n",
       " -0.9408659338951111,\n",
       " 0.4141699969768524,\n",
       " -0.3857289254665375,\n",
       " -0.5354077219963074,\n",
       " -0.9935122728347778,\n",
       " 0.5967322587966919,\n",
       " 0.18807627260684967,\n",
       " 0.5891730785369873,\n",
       " -2.7994704246520996,\n",
       " 0.06927688419818878,\n",
       " -0.4341685175895691,\n",
       " -0.46272146701812744,\n",
       " -1.4816914796829224,\n",
       " 0.17224113643169403,\n",
       " -0.7952711582183838,\n",
       " 0.1565711349248886,\n",
       " -0.17619657516479492,\n",
       " -1.1251672506332397,\n",
       " 0.44084998965263367,\n",
       " 0.2117849588394165,\n",
       " 0.607968270778656,\n",
       " 0.5275800824165344,\n",
       " -2.5019965171813965,\n",
       " 0.8624271154403687,\n",
       " -1.641371250152588,\n",
       " 0.30239078402519226,\n",
       " 0.7061131596565247,\n",
       " 0.9392879605293274,\n",
       " 1.1751068830490112,\n",
       " -0.44697341322898865,\n",
       " 0.16371378302574158,\n",
       " 0.18007510900497437,\n",
       " -0.7350637316703796,\n",
       " 1.7030221223831177,\n",
       " -1.60462486743927,\n",
       " 0.8072414398193359,\n",
       " 0.964353084564209,\n",
       " 0.6116541028022766,\n",
       " -0.17406722903251648,\n",
       " -0.17259259521961212,\n",
       " 0.15400029718875885,\n",
       " 0.8594483733177185,\n",
       " 2.2979836463928223,\n",
       " 0.4389071464538574,\n",
       " -0.08239348232746124,\n",
       " -0.07780949026346207,\n",
       " -0.3604668080806732,\n",
       " 0.15341970324516296,\n",
       " -0.4770628809928894,\n",
       " -0.0032782177440822124,\n",
       " -0.7393946051597595,\n",
       " -2.506293535232544,\n",
       " 0.49191826581954956,\n",
       " 3.4410858154296875,\n",
       " -1.8427224159240723,\n",
       " -0.08678047358989716,\n",
       " 0.9888793230056763,\n",
       " 0.12858846783638,\n",
       " -0.1798998862504959,\n",
       " -1.2981926202774048,\n",
       " 0.056789595633745193,\n",
       " 0.43115270137786865,\n",
       " -1.0245251655578613,\n",
       " 0.7432888150215149,\n",
       " -0.5064881443977356,\n",
       " -0.7477448582649231,\n",
       " 0.8232648968696594,\n",
       " -0.7917765378952026,\n",
       " -1.022305965423584,\n",
       " 0.6067676544189453,\n",
       " 0.42833808064460754,\n",
       " 0.6021357774734497,\n",
       " -1.1802546977996826,\n",
       " -0.04208596795797348,\n",
       " 0.4021078050136566,\n",
       " -0.8116324543952942,\n",
       " 0.5729112029075623,\n",
       " -0.2133590281009674,\n",
       " -0.5848338603973389,\n",
       " 0.7946098446846008,\n",
       " 0.6351840496063232,\n",
       " 2.0756003856658936,\n",
       " 0.5463817715644836,\n",
       " -0.8124914169311523,\n",
       " -0.3125064969062805,\n",
       " -0.6530667543411255,\n",
       " -0.7634136080741882,\n",
       " -0.8110442757606506,\n",
       " 1.5085073709487915,\n",
       " 0.6508628129959106,\n",
       " -0.5743792653083801,\n",
       " -0.3072876036167145,\n",
       " -0.09122401475906372,\n",
       " 0.4705686867237091,\n",
       " 0.1905357539653778,\n",
       " -1.2731648683547974,\n",
       " -0.19578921794891357,\n",
       " -0.8084468245506287,\n",
       " 1.1928925514221191,\n",
       " 0.3344437777996063,\n",
       " 0.12579330801963806,\n",
       " -0.6586080193519592,\n",
       " -0.9998146891593933,\n",
       " 1.5072047710418701,\n",
       " -0.2584979236125946,\n",
       " -0.9047114253044128,\n",
       " -0.880154013633728,\n",
       " 0.5550758838653564,\n",
       " -0.6474974751472473,\n",
       " 0.823798656463623,\n",
       " -1.3436980247497559,\n",
       " -1.804249882698059,\n",
       " 0.9540518522262573,\n",
       " 0.5259464383125305,\n",
       " -0.5654914379119873,\n",
       " 0.6823544502258301,\n",
       " -0.40185388922691345,\n",
       " 0.7578904628753662,\n",
       " -0.3485719561576843,\n",
       " -0.09185390919446945,\n",
       " 0.6346330046653748,\n",
       " -0.6948678493499756,\n",
       " 0.6760465502738953,\n",
       " 1.0902458429336548,\n",
       " -0.22310754656791687,\n",
       " -1.1856155395507812,\n",
       " 0.8424931168556213,\n",
       " -0.4015697240829468,\n",
       " -0.9545964598655701,\n",
       " -2.8482303619384766,\n",
       " -0.7440325021743774,\n",
       " 0.12159784883260727,\n",
       " 0.8282284736633301,\n",
       " 0.1928967386484146,\n",
       " -0.8216668367385864,\n",
       " 1.8696012496948242,\n",
       " -0.5916454195976257,\n",
       " -1.525747299194336,\n",
       " -0.7771559357643127,\n",
       " 0.5371532440185547,\n",
       " -0.7319820523262024,\n",
       " 0.9813814163208008,\n",
       " 0.38649171590805054,\n",
       " 0.23320308327674866,\n",
       " 0.5546033978462219,\n",
       " 1.4493472576141357,\n",
       " 1.6451208591461182,\n",
       " -0.819965124130249,\n",
       " -0.7190219163894653,\n",
       " 0.016437198966741562,\n",
       " -0.046896982938051224,\n",
       " -0.9534209966659546,\n",
       " -1.1623809337615967,\n",
       " -1.0769671201705933,\n",
       " 1.1867607831954956,\n",
       " -0.40215879678726196,\n",
       " -0.6704773902893066,\n",
       " -2.301255226135254,\n",
       " -0.5853632092475891,\n",
       " 0.3260524570941925,\n",
       " -0.22350166738033295,\n",
       " -0.22181819379329681,\n",
       " 0.2890901267528534,\n",
       " 0.1761530339717865,\n",
       " -0.39572760462760925,\n",
       " -1.0944510698318481,\n",
       " 0.6536020040512085,\n",
       " -0.1614430695772171,\n",
       " 0.2651200592517853,\n",
       " 0.842889666557312,\n",
       " 0.40781036019325256,\n",
       " -1.0191118717193604,\n",
       " 0.3181176781654358,\n",
       " 0.4298928678035736,\n",
       " -0.27480727434158325,\n",
       " -0.2563297152519226,\n",
       " 0.8398095369338989,\n",
       " 0.11824318021535873,\n",
       " 0.2735201418399811,\n",
       " 0.6895275115966797,\n",
       " -1.0167790651321411,\n",
       " -0.7837038040161133,\n",
       " 0.18975606560707092,\n",
       " 0.18845424056053162,\n",
       " 0.7386869788169861,\n",
       " 0.2222444713115692,\n",
       " 1.47433340549469,\n",
       " -0.2336088865995407,\n",
       " -1.0119489431381226,\n",
       " 0.14565715193748474,\n",
       " 0.626591145992279,\n",
       " 1.7322978973388672,\n",
       " -1.4753845930099487,\n",
       " 0.6071822047233582,\n",
       " 1.0919864177703857,\n",
       " -1.843854546546936,\n",
       " -0.314359575510025,\n",
       " 0.328809529542923,\n",
       " -0.880129337310791,\n",
       " -0.46780526638031006,\n",
       " -0.18138492107391357,\n",
       " 0.4728871285915375,\n",
       " 0.40826424956321716,\n",
       " 0.7171857953071594,\n",
       " -0.38055896759033203,\n",
       " -0.7229426503181458,\n",
       " 0.07656793296337128,\n",
       " -0.39867132902145386,\n",
       " 0.08265137672424316,\n",
       " 0.6706905961036682,\n",
       " 0.8346748948097229,\n",
       " -0.5265915393829346,\n",
       " 0.15380613505840302,\n",
       " 1.2352949380874634,\n",
       " 1.0996404886245728,\n",
       " 0.9142279028892517,\n",
       " -0.33649441599845886,\n",
       " 0.37729042768478394,\n",
       " 0.5871967673301697,\n",
       " -1.1344228982925415,\n",
       " -0.2763708829879761,\n",
       " -0.6315419673919678,\n",
       " 0.26223209500312805,\n",
       " 0.08688092976808548,\n",
       " -0.7050873637199402,\n",
       " -2.0061941146850586,\n",
       " 0.3683731257915497,\n",
       " 0.4895702004432678,\n",
       " -0.2531694769859314,\n",
       " -0.958836555480957,\n",
       " -0.42992228269577026,\n",
       " 1.1455292701721191,\n",
       " 1.0341497659683228,\n",
       " 1.159061074256897,\n",
       " 0.008549162186682224,\n",
       " 0.6476143002510071,\n",
       " -0.1926565319299698,\n",
       " -0.6122837662696838,\n",
       " 0.45074766874313354,\n",
       " -0.24778035283088684,\n",
       " 0.7724628448486328,\n",
       " -0.2526545226573944,\n",
       " -0.6884884238243103,\n",
       " -0.21608734130859375,\n",
       " 0.1916929930448532,\n",
       " -1.3459640741348267,\n",
       " 0.12841670215129852,\n",
       " 0.8016535639762878,\n",
       " -0.6119940280914307,\n",
       " -0.7297781705856323,\n",
       " -0.33283430337905884,\n",
       " -1.2033771276474,\n",
       " -0.9849039912223816,\n",
       " -0.15880201756954193,\n",
       " 0.35805729031562805,\n",
       " 0.22251708805561066,\n",
       " -0.6513584852218628,\n",
       " -1.4114909172058105,\n",
       " -0.7588666081428528,\n",
       " -1.5648741722106934,\n",
       " 0.5461246967315674,\n",
       " 0.03708362951874733,\n",
       " 0.7152986526489258,\n",
       " 1.4154859781265259,\n",
       " -0.3098445236682892,\n",
       " 0.12241584062576294,\n",
       " 1.2789822816848755,\n",
       " -0.11591894179582596,\n",
       " -0.09444176405668259,\n",
       " 1.3990880250930786,\n",
       " 0.6329914927482605,\n",
       " -0.18146926164627075,\n",
       " 0.0448523573577404,\n",
       " -0.7052241563796997,\n",
       " -0.31226181983947754,\n",
       " 0.4687595069408417,\n",
       " 1.8598535060882568,\n",
       " 0.37904489040374756,\n",
       " -0.12115895748138428,\n",
       " 0.5593867897987366,\n",
       " -5.111108779907227,\n",
       " 0.7978270649909973,\n",
       " 0.21036510169506073,\n",
       " 0.9169880747795105,\n",
       " -0.24761465191841125,\n",
       " -0.047991231083869934,\n",
       " -0.234040305018425,\n",
       " -0.7682415843009949,\n",
       " 0.3568955063819885,\n",
       " 0.4271616041660309,\n",
       " 0.10612471401691437,\n",
       " -0.24501316249370575,\n",
       " 0.42149433493614197,\n",
       " 0.711040735244751,\n",
       " -0.3111281096935272,\n",
       " 0.8136157393455505,\n",
       " 1.20625901222229,\n",
       " -4.034509658813477,\n",
       " 0.2805298864841461,\n",
       " 0.15552429854869843,\n",
       " 1.8613033294677734,\n",
       " 2.234919786453247,\n",
       " -0.20804297924041748,\n",
       " -0.851081132888794,\n",
       " 0.2892003059387207,\n",
       " -0.18786309659481049,\n",
       " -0.13997964560985565,\n",
       " 1.2623622417449951,\n",
       " -1.2108064889907837,\n",
       " -0.922492265701294,\n",
       " 0.6441894173622131,\n",
       " -1.0464887619018555,\n",
       " -0.24383053183555603,\n",
       " 0.6592520475387573,\n",
       " 0.33784589171409607,\n",
       " -0.5389774441719055,\n",
       " -0.4847261905670166,\n",
       " -0.7241610884666443,\n",
       " 1.0992766618728638,\n",
       " -0.4885343909263611,\n",
       " 0.4196927845478058,\n",
       " -2.3707587718963623,\n",
       " -0.3170279264450073,\n",
       " -0.24743779003620148,\n",
       " 0.3652644455432892,\n",
       " -1.2821342945098877,\n",
       " -1.2562205791473389,\n",
       " -0.28689146041870117,\n",
       " -0.967836320400238,\n",
       " -0.29947859048843384,\n",
       " 1.004528522491455,\n",
       " -1.38960862159729,\n",
       " 0.5897483825683594,\n",
       " 0.7149785757064819,\n",
       " 0.8354105353355408,\n",
       " 1.4514912366867065,\n",
       " 2.150261402130127,\n",
       " -1.8025445938110352,\n",
       " -0.33574655652046204,\n",
       " -0.3298815190792084,\n",
       " -0.6086260676383972,\n",
       " -0.6853430867195129,\n",
       " -0.7963055372238159,\n",
       " -0.01493183895945549,\n",
       " -0.872596025466919,\n",
       " 0.21395021677017212,\n",
       " 0.11704301834106445,\n",
       " 0.36121904850006104,\n",
       " 1.4298077821731567,\n",
       " -0.682191789150238,\n",
       " -0.595582127571106,\n",
       " 0.9669266939163208,\n",
       " 0.8960002660751343,\n",
       " 0.2886269986629486,\n",
       " 1.3963996171951294,\n",
       " 0.6605058312416077,\n",
       " 1.4222742319107056,\n",
       " 0.6527330279350281,\n",
       " 0.3760072588920593,\n",
       " 0.8996003270149231,\n",
       " 1.2234381437301636,\n",
       " -0.44498080015182495,\n",
       " 1.3429282903671265,\n",
       " -0.2956184148788452,\n",
       " -0.6748013496398926,\n",
       " 1.3323956727981567,\n",
       " 1.7256089448928833,\n",
       " -2.700883626937866,\n",
       " -0.8850659728050232,\n",
       " -0.896906316280365,\n",
       " 0.27757033705711365,\n",
       " 1.0247422456741333,\n",
       " -0.465270072221756,\n",
       " 0.06935660541057587,\n",
       " -1.5608059167861938,\n",
       " -1.7505229711532593,\n",
       " -0.9927108883857727,\n",
       " 0.38135236501693726,\n",
       " -0.7759039402008057,\n",
       " 2.3056113719940186,\n",
       " -1.2868478298187256,\n",
       " 0.6056578755378723,\n",
       " -1.9102222919464111,\n",
       " -0.6824241876602173,\n",
       " 0.5143016576766968,\n",
       " -2.4433257579803467,\n",
       " 1.9132403135299683,\n",
       " -0.7153497338294983,\n",
       " 1.7363024950027466,\n",
       " -0.0420510396361351,\n",
       " -0.2122897505760193,\n",
       " 0.5097864270210266,\n",
       " 0.36486169695854187,\n",
       " -0.5492128729820251,\n",
       " 0.8786877989768982,\n",
       " 0.2016657590866089,\n",
       " -0.8770069479942322,\n",
       " -0.574142575263977,\n",
       " -0.885856032371521,\n",
       " -0.6635398864746094,\n",
       " 0.8671613335609436,\n",
       " 0.216975599527359,\n",
       " 0.21230106055736542,\n",
       " -0.6541008949279785,\n",
       " -0.9661696553230286,\n",
       " 0.058817267417907715,\n",
       " 0.7942443490028381,\n",
       " 2.2810001373291016,\n",
       " 0.08656420558691025,\n",
       " -0.5125558376312256,\n",
       " -1.2763620615005493,\n",
       " -1.2411556243896484,\n",
       " 0.21991394460201263,\n",
       " 2.1405436992645264,\n",
       " -0.6582120656967163,\n",
       " -0.6530179977416992,\n",
       " 1.0614904165267944,\n",
       " 0.9732920527458191,\n",
       " -0.2589954733848572,\n",
       " -0.6302557587623596,\n",
       " -0.4440767467021942,\n",
       " -0.8718052506446838,\n",
       " -0.2806229889392853,\n",
       " -1.2379792928695679,\n",
       " 2.6862902641296387,\n",
       " -1.0113229751586914,\n",
       " 1.6139576435089111,\n",
       " -0.25136834383010864,\n",
       " -0.5652565956115723,\n",
       " 0.5376963019371033,\n",
       " 0.5711355805397034,\n",
       " 0.42399290204048157,\n",
       " 0.9474461674690247,\n",
       " -0.8561933636665344,\n",
       " 1.5856313705444336,\n",
       " 0.2343696504831314,\n",
       " -0.9501887559890747,\n",
       " -1.1748688220977783,\n",
       " -0.5352539420127869,\n",
       " -0.9661072492599487,\n",
       " 0.6267427206039429,\n",
       " -1.44389009475708,\n",
       " 0.8636653423309326,\n",
       " 0.647675633430481,\n",
       " 1.21027410030365,\n",
       " 0.9610452055931091,\n",
       " -0.5922274589538574,\n",
       " 0.673187255859375,\n",
       " 0.8179163932800293,\n",
       " -0.89859539270401,\n",
       " -0.42926025390625,\n",
       " -0.8649077415466309,\n",
       " -0.9103599786758423,\n",
       " 1.7093344926834106,\n",
       " 0.18947166204452515,\n",
       " -0.7088713049888611,\n",
       " 0.9503559470176697,\n",
       " 0.6814643144607544,\n",
       " 0.6919249892234802,\n",
       " 0.7356342673301697,\n",
       " -0.36361637711524963,\n",
       " -0.17962121963500977,\n",
       " 0.6579861044883728,\n",
       " -0.11012012511491776,\n",
       " -0.9297372698783875,\n",
       " -2.2039129734039307,\n",
       " 1.2201777696609497,\n",
       " -0.7849518656730652,\n",
       " -0.13802684843540192,\n",
       " -1.124091386795044,\n",
       " 0.4689529240131378,\n",
       " 0.7864716053009033,\n",
       " -0.03560952469706535,\n",
       " -0.4086965024471283,\n",
       " -0.9170628190040588,\n",
       " 0.8327720165252686,\n",
       " 0.8785889148712158,\n",
       " 0.5221592783927917,\n",
       " -0.07530361413955688,\n",
       " 0.208272323012352,\n",
       " 0.31058257818222046,\n",
       " -0.633495569229126,\n",
       " 0.8427215814590454,\n",
       " 1.4017252922058105,\n",
       " 0.7871968746185303,\n",
       " 0.07245273888111115,\n",
       " 0.5176593065261841,\n",
       " 0.7853600382804871,\n",
       " 0.2680628299713135,\n",
       " -0.9324954748153687,\n",
       " -0.20149514079093933,\n",
       " -1.5504838228225708,\n",
       " 0.3406698405742645,\n",
       " 1.900893211364746,\n",
       " -0.9409016966819763,\n",
       " 0.16577671468257904,\n",
       " -0.12532226741313934,\n",
       " 0.8055346608161926,\n",
       " 0.9573560357093811,\n",
       " -0.8028380274772644,\n",
       " -0.5788918137550354,\n",
       " -1.3859165906906128,\n",
       " 1.3789446353912354,\n",
       " -0.24626411497592926,\n",
       " -0.06426169723272324,\n",
       " -0.6656021475791931,\n",
       " -1.257557988166809,\n",
       " 0.28905242681503296,\n",
       " -1.1413108110427856,\n",
       " -0.20913143455982208,\n",
       " -0.045739445835351944,\n",
       " -0.977321207523346,\n",
       " -0.2595549523830414,\n",
       " -1.111936092376709,\n",
       " 0.6708475947380066,\n",
       " 0.7382739186286926,\n",
       " -0.2759149968624115,\n",
       " -0.3274737596511841,\n",
       " -0.1695491522550583,\n",
       " -0.6399424076080322,\n",
       " -1.7441656589508057,\n",
       " 0.247444748878479,\n",
       " -0.4708102345466614,\n",
       " -0.3421637713909149,\n",
       " 0.8016922473907471,\n",
       " 0.6566365957260132,\n",
       " -0.6192294955253601,\n",
       " -0.4456752836704254,\n",
       " -0.781851053237915,\n",
       " 0.8520079255104065,\n",
       " -0.1588556170463562,\n",
       " 0.2269890159368515,\n",
       " 0.14297841489315033,\n",
       " 0.7955396175384521,\n",
       " 1.2050080299377441,\n",
       " -0.6790421605110168,\n",
       " 0.039830464869737625,\n",
       " -2.8024826049804688,\n",
       " -1.348879098892212,\n",
       " 1.0374901294708252,\n",
       " 0.016482604667544365,\n",
       " -0.37291088700294495,\n",
       " -0.3768995702266693,\n",
       " -1.3390765190124512,\n",
       " -0.6543777585029602,\n",
       " 0.21055418252944946,\n",
       " 0.11747138947248459,\n",
       " 1.4163020849227905,\n",
       " 0.7888811826705933,\n",
       " -0.14230990409851074,\n",
       " 1.2989935874938965,\n",
       " -0.016455141827464104,\n",
       " 0.04872138053178787,\n",
       " 0.12955185770988464,\n",
       " -1.5094609260559082,\n",
       " -0.8129079341888428,\n",
       " 0.07292789220809937,\n",
       " 0.10929010063409805,\n",
       " 0.6447180509567261,\n",
       " -0.46497395634651184,\n",
       " -0.81052166223526,\n",
       " 0.5890234708786011,\n",
       " 0.12224951386451721,\n",
       " -0.8274109363555908,\n",
       " 0.9815533757209778,\n",
       " -1.3501768112182617,\n",
       " 0.031410202383995056,\n",
       " 2.4052157402038574,\n",
       " 0.5867942571640015,\n",
       " 0.1959223747253418,\n",
       " 0.20297099649906158,\n",
       " 0.829057514667511,\n",
       " 0.4638220965862274,\n",
       " 0.5637644529342651,\n",
       " 1.0582395792007446,\n",
       " 0.9569747447967529,\n",
       " -0.26849520206451416,\n",
       " -0.2919066548347473,\n",
       " -0.8621677160263062,\n",
       " 0.7740675806999207,\n",
       " 1.1133602857589722,\n",
       " -0.7480517029762268,\n",
       " -0.49595364928245544,\n",
       " 0.5465604066848755,\n",
       " 0.9526727795600891,\n",
       " 1.367809772491455,\n",
       " -0.6834889054298401,\n",
       " -0.7067323327064514,\n",
       " 0.04995846375823021,\n",
       " 0.0998171716928482,\n",
       " 0.11842183768749237,\n",
       " 0.9900797605514526,\n",
       " -0.8691198229789734,\n",
       " -0.38174593448638916,\n",
       " -0.12012307345867157,\n",
       " 0.24394473433494568,\n",
       " -0.707531750202179,\n",
       " 1.6696336269378662,\n",
       " 0.44187408685684204,\n",
       " -2.4958627223968506,\n",
       " 0.1430639773607254,\n",
       " -0.40608659386634827,\n",
       " 0.8621616363525391,\n",
       " -0.5488449335098267,\n",
       " 0.019157905131578445,\n",
       " -0.5277200937271118,\n",
       " 0.051894135773181915,\n",
       " 0.7003795504570007,\n",
       " -0.6961079239845276,\n",
       " -0.4152343273162842,\n",
       " 0.10042072832584381,\n",
       " 0.09947256743907928,\n",
       " 0.7127540707588196,\n",
       " -0.9828416109085083,\n",
       " 0.6060328483581543,\n",
       " 0.9327385425567627,\n",
       " -0.45655468106269836,\n",
       " -0.892657458782196,\n",
       " 0.37234729528427124,\n",
       " -0.5702071189880371,\n",
       " 0.12482878565788269,\n",
       " 0.767132043838501,\n",
       " 0.7696143388748169,\n",
       " -0.9928449392318726,\n",
       " -0.9152206182479858,\n",
       " -0.5325344800949097,\n",
       " 0.1935640126466751,\n",
       " -0.19717030227184296,\n",
       " 0.6128087043762207,\n",
       " 0.19418595731258392,\n",
       " -0.24110397696495056,\n",
       " -0.801719605922699,\n",
       " -0.7895933985710144,\n",
       " -2.256819009780884,\n",
       " -1.3972253799438477,\n",
       " -0.4944716691970825,\n",
       " 0.14396226406097412,\n",
       " -0.4897916615009308,\n",
       " 0.2691393494606018,\n",
       " 0.8772532343864441,\n",
       " -1.3599486351013184,\n",
       " -1.3036246299743652,\n",
       " 0.45129773020744324,\n",
       " -0.7256576418876648,\n",
       " 0.5197629928588867,\n",
       " -0.05367869511246681,\n",
       " -0.44499245285987854,\n",
       " -0.9020005464553833,\n",
       " 0.17168660461902618,\n",
       " 0.17869652807712555,\n",
       " 1.2322427034378052,\n",
       " -0.018823908641934395,\n",
       " 0.886997640132904,\n",
       " 0.9060299396514893,\n",
       " 2.951342821121216,\n",
       " 2.7830300331115723,\n",
       " 1.0550504922866821,\n",
       " 0.279653936624527,\n",
       " 0.3351323902606964,\n",
       " 0.1356528401374817,\n",
       " -0.2426382452249527,\n",
       " -0.07476266473531723,\n",
       " -0.13513144850730896,\n",
       " 2.109971761703491,\n",
       " -1.8570066690444946,\n",
       " 1.0166196823120117,\n",
       " 1.2244848012924194,\n",
       " -0.6280710101127625,\n",
       " -0.0992661565542221,\n",
       " 0.22595053911209106,\n",
       " 0.7234442234039307,\n",
       " -2.1257150173187256,\n",
       " -0.12369779497385025,\n",
       " -0.8225164413452148,\n",
       " -0.7220141887664795,\n",
       " -0.5797247290611267,\n",
       " -4.281345367431641,\n",
       " -1.1121032238006592,\n",
       " 2.3579421043395996,\n",
       " 0.08868681639432907,\n",
       " -0.7196208834648132,\n",
       " -0.2016901820898056,\n",
       " 0.6842446327209473,\n",
       " -0.9258179068565369,\n",
       " -0.4852851629257202,\n",
       " 0.511873722076416,\n",
       " 0.35226520895957947,\n",
       " 1.5747400522232056,\n",
       " -0.6953518986701965,\n",
       " 0.11483114957809448,\n",
       " 0.6742953062057495,\n",
       " -0.903285026550293,\n",
       " -0.6667497754096985,\n",
       " 0.7318711280822754,\n",
       " -0.42871031165122986,\n",
       " 0.04878583550453186,\n",
       " 1.572149634361267,\n",
       " -1.04462730884552,\n",
       " -0.7737109661102295,\n",
       " -0.12363819032907486,\n",
       " -0.6208552122116089,\n",
       " 0.6041929721832275,\n",
       " -0.27237236499786377,\n",
       " 0.47600075602531433,\n",
       " 1.6398814916610718,\n",
       " -0.6357022523880005,\n",
       " -0.929531991481781,\n",
       " -0.16053664684295654,\n",
       " -0.5448906421661377,\n",
       " 0.11701572686433792,\n",
       " 1.2805917263031006,\n",
       " 0.5782173871994019,\n",
       " 0.6720651984214783,\n",
       " 1.5684146881103516,\n",
       " -1.2075188159942627,\n",
       " -0.3099500834941864,\n",
       " 1.179526448249817,\n",
       " 1.5003606081008911,\n",
       " 1.6724517345428467,\n",
       " 0.20729994773864746,\n",
       " -0.9595357775688171,\n",
       " -2.827786922454834,\n",
       " -1.414141058921814,\n",
       " 0.013677036389708519,\n",
       " 2.498063087463379,\n",
       " -1.1610430479049683,\n",
       " 0.023202521726489067,\n",
       " 1.0821146965026855,\n",
       " -1.8829413652420044,\n",
       " 0.8740676045417786,\n",
       " 1.2359849214553833,\n",
       " 1.7753088474273682,\n",
       " 0.13060811161994934,\n",
       " -0.47503066062927246,\n",
       " -0.43160003423690796,\n",
       " 0.39232587814331055,\n",
       " 0.8870952725410461,\n",
       " -0.08458174765110016,\n",
       " 0.4178807735443115,\n",
       " 0.8134139180183411,\n",
       " -0.9852147698402405,\n",
       " 0.7404794692993164,\n",
       " -0.6107630133628845,\n",
       " 0.5037840604782104,\n",
       " -1.9008649587631226,\n",
       " -0.10317669808864594,\n",
       " -0.6571851372718811,\n",
       " 0.5732517838478088,\n",
       " -0.20615242421627045,\n",
       " 1.377864956855774,\n",
       " -0.8624808192253113,\n",
       " 0.15402917563915253,\n",
       " -0.7712611556053162,\n",
       " -0.8882291316986084,\n",
       " -0.8698855638504028,\n",
       " -1.1524571180343628,\n",
       " 0.9731161594390869,\n",
       " -0.7225440740585327,\n",
       " -1.5419398546218872,\n",
       " -0.027034882456064224,\n",
       " -0.8258040547370911,\n",
       " 1.6790508031845093,\n",
       " 1.704403042793274,\n",
       " 1.6161353588104248,\n",
       " -0.1349148154258728,\n",
       " -0.6088611483573914,\n",
       " -0.7467027902603149,\n",
       " -0.47415032982826233,\n",
       " 0.39398589730262756,\n",
       " 0.6155907511711121,\n",
       " -0.5808317065238953,\n",
       " 0.2624576687812805,\n",
       " 0.3553268313407898,\n",
       " -0.8904435038566589,\n",
       " -0.29302331805229187,\n",
       " 0.9545555114746094,\n",
       " -0.9386886954307556,\n",
       " -1.8164169788360596,\n",
       " 0.3928176164627075,\n",
       " 1.0733314752578735,\n",
       " -0.47164323925971985,\n",
       " 0.24989156424999237,\n",
       " -0.6041609048843384,\n",
       " -0.8325937986373901,\n",
       " -0.22616563737392426,\n",
       " 0.03299855813384056,\n",
       " -1.9259299039840698,\n",
       " -0.5992200374603271,\n",
       " 2.543243885040283,\n",
       " -0.11230432242155075,\n",
       " -0.6050367951393127,\n",
       " -1.0514936447143555,\n",
       " -0.6186726689338684,\n",
       " -0.6158215403556824,\n",
       " 5.507618427276611,\n",
       " 1.280713677406311,\n",
       " 0.002957651624456048,\n",
       " -0.849952757358551,\n",
       " 0.9255075454711914,\n",
       " 1.1064380407333374,\n",
       " -0.032604582607746124,\n",
       " 2.820589065551758,\n",
       " -1.8163676261901855,\n",
       " 0.9629178643226624,\n",
       " 2.0545997619628906,\n",
       " -0.06255912035703659,\n",
       " -0.3325849175453186,\n",
       " 1.763187050819397,\n",
       " -1.2086881399154663,\n",
       " 0.8664764761924744,\n",
       " -0.32792502641677856,\n",
       " -2.2151169776916504,\n",
       " 0.07103404402732849,\n",
       " 0.4246584475040436,\n",
       " 0.2684951424598694,\n",
       " -0.691235363483429,\n",
       " ...]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_surrogate_model_return_adveserial_samples(surrogate_model, dataset, embeddings, contrastive_loss):\n",
    "    optimizer = torch.optim.Adam(surrogate_model.parameters(), lr=1e-3)\n",
    "    surrogate_model.train()\n",
    "    batch_size = 32\n",
    "    num_epochs = 10\n",
    "    loss = 0.0\n",
    "    loss_copy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(1000):\n",
    "            input = dataset[i].unsqueeze(0)\n",
    "            output = surrogate_model(input)\n",
    "            embedding = torch.tensor(embeddings[i]).unsqueeze(0)\n",
    "            loss += contrastive_loss(output, embedding)\n",
    "                \n",
    "            if (i+1) % batch_size == 0:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_copy = loss.item()\n",
    "                loss = 0.0\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {loss_copy}\")\n",
    "        \n",
    "    print(\"Training done\")                \n",
    "    # Create adversarial samples\n",
    "    adversarial_samples = []\n",
    "    epsilon = 0.1\n",
    "    for i in range(1000):\n",
    "        input = dataset[i][0].unsqueeze(0)\n",
    "        input.requires_grad = True\n",
    "        output = surrogate_model(input)\n",
    "        embedding = torch.tensor(embeddings[i]).unsqueeze(0)\n",
    "        loss = contrastive_loss(output, embedding)\n",
    "        loss.backward()\n",
    "        adv_sample =  input + epsilon*torch.sign(input.grad)\n",
    "        adversarial_samples.append(adv_sample[0])\n",
    "    \n",
    "    return surrogate_model, adversarial_samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_api_tensor(adversarial_samples):\n",
    "    adversarial_output = []\n",
    "    for i in range(13):\n",
    "        adversarial_output.extend(model_stealing_tensor(adversarial_samples[i*1000:(i+1)*1000], port=PORT))\n",
    "        # wait for 1 minute\n",
    "        break\n",
    "        time.sleep(60)\n",
    "    return adversarial_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def query_api(samples):\n",
    "    output = []\n",
    "    for i in range(13):\n",
    "        output.extend(model_stealing(samples[i*1000:(i+1)*1000], port=PORT))\n",
    "        break\n",
    "        # wait for 1 minute\n",
    "        time.sleep(60)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[192], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mquery_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[190], line 7\u001b[0m, in \u001b[0;36mquery_api\u001b[1;34m(samples)\u001b[0m\n\u001b[0;32m      5\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(model_stealing(samples[i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m], port\u001b[38;5;241m=\u001b[39mPORT))\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# wait for 1 minute\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out = query_api(dataset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x261de0e3580>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[220], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m SurrogateModel()\n\u001b[1;32m----> 2\u001b[0m model, adversarial_samples \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_surrogate_model_return_adveserial_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimages_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrastive_loss\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[214], line 20\u001b[0m, in \u001b[0;36mtrain_surrogate_model_return_adveserial_samples\u001b[1;34m(surrogate_model, dataset, embeddings, contrastive_loss)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m batch_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     22\u001b[0m     loss_copy \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\autograd\\__init__.py:244\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    235\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    236\u001b[0m     (inputs,)\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[0;32m    241\u001b[0m )\n\u001b[0;32m    243\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[1;32m--> 244\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\autograd\\__init__.py:127\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m    121\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    122\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m         )\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m    126\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 127\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     )\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SurrogateModel()\n",
    "model, adversarial_samples = train_surrogate_model_return_adveserial_samples(model,images_dataset , out, contrastive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "surrogate_model = SurrogateModel()\n",
    "\n",
    "query_output = query_api_tensor(dataset.imgs)\n",
    "surrogate_model, adversarial_samples = train_surrogate_model_return_adveserial_samples(surrogate_model, images_dataset, query_output, contrastive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_output = query_api_tensor(adversarial_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[233], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, adversarial_samples \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_surrogate_model_return_adveserial_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversarial_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrastive_loss\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[229], line 12\u001b[0m, in \u001b[0;36mtrain_surrogate_model_return_adveserial_samples\u001b[1;34m(surrogate_model, dataset, embeddings, contrastive_loss)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m dataset[i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m surrogate_model(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m embedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m contrastive_loss(output, embedding)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m batch_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model, adversarial_samples = train_surrogate_model_return_adveserial_samples(model, adversarial_samples, query_output, contrastive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_output = model_stealing_tensor(adversarial_samples, port=PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26202fa4d00>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset.imgs[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26203027490>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(adversarial_samples[80].detach().numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13000"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Query the API with the adversarial inputs\n",
    "outputs_adv = torch.stack([api_query(input_adv) for input_adv in inputs_adv])\n",
    "\n",
    "# Retrain the surrogate model with the adversarial examples\n",
    "inputs = torch.cat((inputs, inputs_adv))\n",
    "outputs = torch.cat((outputs, outputs_adv))\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i in range(len(inputs)):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = surrogate(inputs[i].unsqueeze(0))\n",
    "        loss = criterion(output, outputs[i].unsqueeze(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d loss: %.3f' % (epoch + 1, running_loss / len(inputs)))\n",
    "\n",
    "print('Finished Retraining')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
