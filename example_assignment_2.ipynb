{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd:  c:\\Users\\HP\\OneDrive\\Documents\\GitHub\\Trustworthy-Machine-Learning\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# Do install: \n",
    "# conda install onnx\n",
    "# conda install onnxruntime\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import json\n",
    "import io\n",
    "import sys\n",
    "import base64\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple\n",
    "import pickle\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print('cwd: ', cwd)\n",
    "\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if not self.transform is None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### REQUESTING NEW API ###\n",
    "TOKEN = \"75184352\" # to be changed according to your token (given to you for the assignments)\n",
    "\n",
    "# response = requests.get(\"http://34.71.138.79:9090\" + \"/stealing_launch\", headers={\"token\": TOKEN})\n",
    "# answer = response.json()\n",
    "\n",
    "# print(answer)  # {\"seed\": \"SEED\", \"port\": PORT}\n",
    "# if 'detail' in answer:\n",
    "#     sys.exit(1)\n",
    "\n",
    "# # save the values\n",
    "# SEED = str(answer['seed'])\n",
    "# PORT = str(answer['port'])\n",
    "\n",
    "# # SEED = \"1868949\"\n",
    "# # PORT = \"9002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = \"78446225\"\n",
    "PORT = \"9056\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUERYING THE API ###\n",
    "\n",
    "def model_stealing(images, port):\n",
    "    endpoint = \"/query\"\n",
    "    url = f\"http://34.71.138.79:{port}\" + endpoint\n",
    "    image_data = []\n",
    "    \n",
    "    for img in images:\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr.seek(0)\n",
    "        img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "        image_data.append(img_base64)\n",
    "    \n",
    "    payload = json.dumps(image_data)\n",
    "    response = requests.get(url, files={\"file\": payload}, headers={\"token\": TOKEN})\n",
    "    if response.status_code == 200:\n",
    "        representation = response.json()[\"representations\"]\n",
    "        return representation\n",
    "    else:\n",
    "        raise Exception(\n",
    "            f\"Model stealing failed. Code: {response.status_code}, content: {response.json()}\"\n",
    "        )\n",
    "\n",
    "dataset = torch.load(\"ModelStealingPub.pt\")\n",
    "out = model_stealing([dataset.imgs[idx] for idx in range(1000)], port=PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "def model_stealing_tensor(images, port):\n",
    "    endpoint = \"/query\"\n",
    "    url = f\"http://34.71.138.79:{port}\" + endpoint\n",
    "    \n",
    "    to_pil = ToPILImage()\n",
    "\n",
    "    \n",
    "    image_data = []\n",
    "    for img_tensor in images:\n",
    "        img = to_pil(img_tensor)  # Convert tensor to PIL Image\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr.seek(0)\n",
    "        img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "        image_data.append(img_base64)\n",
    "    \n",
    "    payload = json.dumps(image_data)\n",
    "    response = requests.get(url, files={\"file\": payload}, headers={\"token\": TOKEN})\n",
    "    if response.status_code == 200:\n",
    "        representation = response.json()[\"representations\"]\n",
    "        return representation\n",
    "    else:\n",
    "        raise Exception(\n",
    "            f\"Model stealing failed. Code: {response.status_code}, content: {response.json()}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1024\n",
      "0.21157068014144897\n"
     ]
    }
   ],
   "source": [
    "# 1000 representations in a list\n",
    "print(len(out))\n",
    "\n",
    "# representation 1\n",
    "print(len(out[0]))\n",
    "\n",
    "# first element in the representation\n",
    "print(out[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Store the output in a file.\n",
    "# Be careful to store all the outputs from the API since the number of queries is limited.\n",
    "with open('out.pickle', 'wb') as handle:\n",
    "    pickle.dump(out, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Restore the output from the file.\n",
    "with open('out.pickle', 'rb') as handle:\n",
    "    out = pickle.load(handle)\n",
    "\n",
    "print(len(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L2': 34.66728973388672}\n"
     ]
    }
   ],
   "source": [
    "#### SUBMISSION ####\n",
    "\n",
    "# Create a dummy model\n",
    "model = nn.Sequential(nn.Flatten(), nn.Linear(32*32*3, 1024))\n",
    "\n",
    "path = 'dummy_submission.onnx'\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    torch.randn(1, 3, 32, 32),\n",
    "    path,\n",
    "    export_params=True,\n",
    "    input_names=[\"x\"],\n",
    ")\n",
    "\n",
    "#### Tests ####\n",
    "\n",
    "# (these are being ran on the eval endpoint for every submission)\n",
    "with open(path, \"rb\") as f:\n",
    "    model = f.read()\n",
    "    try:\n",
    "        stolen_model = ort.InferenceSession(model)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Invalid model, {e=}\")\n",
    "    try:\n",
    "        out = stolen_model.run(\n",
    "            None, {\"x\": np.random.randn(1, 3, 32, 32).astype(np.float32)}\n",
    "        )[0][0]\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Some issue with the input, {e=}\")\n",
    "    assert out.shape == (1024,), \"Invalid output shape\"\n",
    "\n",
    "# Send the model to the server\n",
    "response = requests.post(\"http://34.71.138.79:9090/stealing\", files={\"file\": open(path, \"rb\")}, headers={\"token\": TOKEN, \"seed\": SEED})\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make a surrogate model\n",
    "# query the API, then use contrastive learning to train a surrogate model\n",
    "# adv image = image + epsilon * sign(d(SM)/d(image))\n",
    "\n",
    "# generate adversarial examples to attack the surrogate model\n",
    "# query the API with the adversarial examples\n",
    "\n",
    "# retrain the surrogate model with the adversarial examples\n",
    "# reapeat the process for a few iterations\n",
    "# then submit the surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a surrogate model with high capacity, input torch.Size([3, 32, 32]) and output torch.Size([1024])\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class SurrogateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SurrogateModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(256 * 4 * 4, 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = SurrogateModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a contrastive loss function\n",
    "def contrastive_loss(output1, output2):\n",
    "    return torch.dist(output1, output2, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(\"ModelStealingPub.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
    "\n",
    "# Convert all images to 3-channel images\n",
    "images = [to_tensor(img.convert(\"RGB\")) for img in dataset.imgs]\n",
    "# Convert the list to a tensor\n",
    "inputs_tensor = torch.stack(images)\n",
    "# Create a TensorDataset\n",
    "images_dataset = TensorDataset(inputs_tensor)\n",
    "# Create a DataLoader\n",
    "images_loader = torch.utils.data.DataLoader(images_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13000, 3, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_surrogate_model_return_adveserial_samples(surrogate_model, dataset, embeddings, contrastive_loss):\n",
    "    optimizer = torch.optim.Adam(surrogate_model.parameters(), lr=1e-3)\n",
    "    surrogate_model.train()\n",
    "    batch_size = 32\n",
    "    num_epochs = 10\n",
    "    loss = 0.0\n",
    "    loss_copy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(1000):\n",
    "            \n",
    "            input = dataset[i][0].unsqueeze(0)\n",
    "            output = surrogate_model(input)\n",
    "            embedding = torch.tensor(embeddings[i]).unsqueeze(0)\n",
    "            loss += contrastive_loss(output, embedding)\n",
    "                \n",
    "            if (i+1) % batch_size == 0:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_copy = loss.item()\n",
    "                loss = 0.0\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {loss_copy}\")\n",
    "        \n",
    "    print(\"Training done\")                \n",
    "    # Create adversarial samples\n",
    "    adversarial_samples = []\n",
    "    epsilon = 0.1\n",
    "    for i in range(1000):\n",
    "        input = dataset[i][0].unsqueeze(0)\n",
    "        input.requires_grad = True\n",
    "        output = surrogate_model(input)\n",
    "        embedding = torch.tensor(embeddings[i]).unsqueeze(0)\n",
    "        loss = contrastive_loss(output, embedding)\n",
    "        loss.backward()\n",
    "        adv_sample =  input + epsilon*torch.sign(input.grad)\n",
    "        adversarial_samples.append(adv_sample[0])\n",
    "    \n",
    "    return surrogate_model, adversarial_samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_surrogate_model_return_adveserial_samples_tensor(surrogate_model, dataset, embeddings, contrastive_loss):\n",
    "    optimizer = torch.optim.Adam(surrogate_model.parameters(), lr=1e-3)\n",
    "    surrogate_model.train()\n",
    "    batch_size = 32\n",
    "    num_epochs = 10\n",
    "    loss = 0.0\n",
    "    loss_copy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(1000):\n",
    "            \n",
    "            input = dataset[i].unsqueeze(0)\n",
    "            output = surrogate_model(input)\n",
    "            embedding = torch.tensor(embeddings[i]).unsqueeze(0)\n",
    "            loss += contrastive_loss(output, embedding)\n",
    "                \n",
    "            if (i+1) % batch_size == 0:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_copy = loss.item()\n",
    "                loss = 0.0\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {loss_copy}\")\n",
    "        \n",
    "    print(\"Training done\")                \n",
    "    # Create adversarial samples\n",
    "    adversarial_samples = []\n",
    "    epsilon = 0.1\n",
    "    for i in range(1000):\n",
    "        input = dataset[i].unsqueeze(0).detach()\n",
    "        input.requires_grad = True\n",
    "        output = surrogate_model(input)\n",
    "        embedding = torch.tensor(embeddings[i]).unsqueeze(0)\n",
    "        loss = contrastive_loss(output, embedding)\n",
    "        loss.backward()\n",
    "        adv_sample =  input + epsilon*torch.sign(input.grad)\n",
    "        adversarial_samples.append(adv_sample[0])\n",
    "    \n",
    "    return surrogate_model, adversarial_samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_api_tensor(adversarial_samples):\n",
    "    adversarial_output = []\n",
    "    for i in range(13):\n",
    "        adversarial_output.extend(model_stealing_tensor(adversarial_samples[i*1000:(i+1)*1000], port=PORT))\n",
    "        # wait for 1 minute\n",
    "        break\n",
    "        time.sleep(60)\n",
    "    return adversarial_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def query_api(samples):\n",
    "    output = []\n",
    "    for i in range(13):\n",
    "        output.extend(model_stealing(samples[i*1000:(i+1)*1000], port=PORT))\n",
    "        break\n",
    "        # wait for 1 minute\n",
    "        time.sleep(60)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = query_api(dataset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x22db088efa0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SurrogateModel()\n",
    "model, adversarial_samples = train_surrogate_model_return_adveserial_samples(model,images_dataset , out, contrastive_loss)\n",
    "out = query_api_tensor(adversarial_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 229.36727905273438\n"
     ]
    }
   ],
   "source": [
    "model, adversarial_samples = train_surrogate_model_return_adveserial_samples_tensor(model,adversarial_samples , out, contrastive_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 318.0881652832031\n",
      "Epoch: 2, Loss: 304.9924011230469\n",
      "Epoch: 3, Loss: 289.10614013671875\n",
      "Epoch: 4, Loss: 272.5647888183594\n",
      "Epoch: 5, Loss: 261.8525695800781\n",
      "Epoch: 6, Loss: 254.76962280273438\n",
      "Epoch: 7, Loss: 247.4232635498047\n",
      "Epoch: 8, Loss: 237.98683166503906\n",
      "Epoch: 9, Loss: 229.0030059814453\n",
      "Epoch: 10, Loss: 222.25184631347656\n",
      "Training done\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 3, 3], expected input[1, 1, 32, 32] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      7\u001b[0m     out \u001b[38;5;241m=\u001b[39m query_api_tensor(adversarial_samples)\n\u001b[1;32m----> 8\u001b[0m     model, adversarial_samples \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_surrogate_model_return_adveserial_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43madversarial_samples\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrastive_loss\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[36], line 11\u001b[0m, in \u001b[0;36mtrain_surrogate_model_return_adveserial_samples\u001b[1;34m(surrogate_model, dataset, embeddings, contrastive_loss)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m dataset[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43msurrogate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(embeddings[i])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     13\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m contrastive_loss(output, embedding)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[25], line 14\u001b[0m, in \u001b[0;36mSurrogateModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mmax_pool2d(x, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 3, 3], expected input[1, 1, 32, 32] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs =10\n",
    "\n",
    "for i in range(epochs):\n",
    "    out = query_api_tensor(adversarial_samples)\n",
    "    model, adversarial_samples = train_surrogate_model_return_adveserial_samples_tensor(model,adversarial_samples , out, contrastive_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "surrogate_model = SurrogateModel()\n",
    "\n",
    "query_output = query_api_tensor(dataset.imgs)\n",
    "surrogate_model, adversarial_samples = train_surrogate_model_return_adveserial_samples(surrogate_model, images_dataset, query_output, contrastive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_output = query_api_tensor(adversarial_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[233], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, adversarial_samples \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_surrogate_model_return_adveserial_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversarial_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrastive_loss\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[229], line 12\u001b[0m, in \u001b[0;36mtrain_surrogate_model_return_adveserial_samples\u001b[1;34m(surrogate_model, dataset, embeddings, contrastive_loss)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m dataset[i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m surrogate_model(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m embedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m contrastive_loss(output, embedding)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m batch_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model, adversarial_samples = train_surrogate_model_return_adveserial_samples(model, adversarial_samples, query_output, contrastive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_output = model_stealing_tensor(adversarial_samples, port=PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26202fa4d00>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset.imgs[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26203027490>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(adversarial_samples[80].detach().numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13000"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
